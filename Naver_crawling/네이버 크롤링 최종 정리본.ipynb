{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c744d2ba",
   "metadata": {},
   "source": [
    "# 네이버 웹툰 크롤링하기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14563f20",
   "metadata": {},
   "source": [
    "## 필요한 라이브러리 호출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62f83c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup as bs\n",
    "from selenium import webdriver\n",
    "from time import sleep\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import re\n",
    "import requests\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from io import BytesIO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "153a631b",
   "metadata": {},
   "source": [
    "## 연재 중인 네이버 웹툰 정보 크롤링"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fa82edd",
   "metadata": {},
   "source": [
    "**함수 만들기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe1446b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naver_crawling(title_list, URL):\n",
    "    driver=webdriver.Chrome('chromedriver.exe')\n",
    "    driver.get(URL)\n",
    "\n",
    "    img_list=[] \n",
    "    artist_list=[] \n",
    "    genre_list=[] \n",
    "    score_list=[]  \n",
    "    story_list=[] \n",
    "\n",
    "    for i in range(len(title_list)):\n",
    "\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        # 제목에 해당하는 엘리먼트 클릭 순서대로 클릭\n",
    "        page=driver.find_elements_by_class_name('title')\n",
    "        page[i].click()\n",
    "\n",
    "        time.sleep(0.01)\n",
    "\n",
    "        #셀레니움으로 열어서 페이지 정보 가져오기\n",
    "        html = driver.page_source\n",
    "        soup = bs(html,'html.parser')\n",
    "\n",
    "        #작품 썸네일 이미지\n",
    "        img=soup.select('#content > div.comicinfo > div.thumb > a > img')[0]['src']\n",
    "        img_list.append(img)\n",
    "\n",
    "        #작가님 닉네임 수집\n",
    "        artist = soup.select('#content > div.comicinfo > div.detail > h2 > span.wrt_nm')\n",
    "        artist_list.append(artist[0].string.strip())\n",
    "\n",
    "        #줄거리 링크 \n",
    "        story=soup.select('#content > div.comicinfo > div.detail > p:nth-child(2)')\n",
    "        story_list.append(story[0].get_text())\n",
    "\n",
    "        #작품 장르 수집\n",
    "        genre = soup.select('#content > div.comicinfo > div.detail > p.detail_info > span.genre')\n",
    "        genre_list.append(genre[0].string)\n",
    "\n",
    "        # 최신 별점 평균 점수 수집 (최대 10화 분량) : 이부분은 참조함\n",
    "        # https://prod.velog.io/@2taesung/wt.gg-%EB%84%A4%EC%9D%B4%EB%B2%84-%EC%9B%B9%ED%88%B0-%ED%81%AC%EB%A1%A4%EB%A7%81\n",
    "        score = soup.find_all('strong')\n",
    "\n",
    "        scorelist=[] ; ii=9\n",
    "        while score[ii].text[0].isnumeric()==True:\n",
    "            scorelist.append(float(score[ii].text))\n",
    "            ii +=1\n",
    "            if len(scorelist) == 3:\n",
    "              break\n",
    "        score_list.append(sum(scorelist)/len(scorelist))\n",
    "\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        driver.back()\n",
    "        \n",
    "        time.sleep(0.2)\n",
    "        \n",
    "        page.clear()\n",
    "        \n",
    "        time.sleep(0.01)\n",
    "        \n",
    "        #데이터 프레임으로 변환\n",
    "        df = pd.DataFrame(zip(title_list, artist_list, genre_list, score_list, story_list,img_list, link_list), \n",
    "                             columns = ['Title', 'Artist', 'Genre', 'Score(recent 10)', 'Story', 'Image', 'Link'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5b65ea2",
   "metadata": {},
   "source": [
    "**연재 중 웹툰 크롤링하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f044f44",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://comic.naver.com/webtoon/weekday.nhn'\n",
    "html = requests.get(URL).text # html 문서 전체를 긁어서 출력해줌, .text는 태그 제외하고 text만 출력되게 함\n",
    "soup = bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef660243",
   "metadata": {},
   "source": [
    "**링크 주소와 제목 가져오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5c3f451",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list = []\n",
    "title_list = []\n",
    "\n",
    "#각 숫자 1~7까지는 월화수목금토일을 의미한다.\n",
    "for i in range(1,8): \n",
    "    tl_tag=soup.select(f'#content > div.list_area.daily_all > div:nth-child({i}) > div > ul > li > a')\n",
    "    \n",
    "    #각 요일의 각 웹툰들에 해당하는 주소와 제목을 가져온다.\n",
    "    for j in range(len(tl_tag)): \n",
    "        title = tl_tag[j]['title']\n",
    "        link = tl_tag[j]['href']\n",
    "        title_list.append(title)\n",
    "        link_list.append(f'https://comic.naver.com{link}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fa59ed",
   "metadata": {},
   "source": [
    "**가져온 제목을 기반으로 필요한 정보 수집하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9478dd5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL='https://comic.naver.com/webtoon/weekday.nhn'\n",
    "df_yonjae  = naver_crawling(title_list, URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef5d081",
   "metadata": {},
   "source": [
    "**데이터 프레임으로 변환하고 csv로 저장하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbddf777",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_yonjae.to_csv('naver_webtoon_real.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548216f7",
   "metadata": {},
   "source": [
    "## 완결 웹툰 크롤링"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5355c4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def naver_crawling_finish(title_list, URL):\n",
    "    driver=webdriver.Chrome('chromedriver.exe')\n",
    "    driver.get(URL)\n",
    "    \n",
    "    img_list=[] \n",
    "    artist_list=[] \n",
    "    genre_list=[] \n",
    "    score_list=[]  \n",
    "    story_list=[] \n",
    "\n",
    "    for i in tqdm(range(1,1283)):\n",
    "        page = driver.find_elements_by_class_name('thumb')\n",
    "        \n",
    "        time.sleep(0.5)\n",
    "\n",
    "        # 제목에 해당하는 엘리먼트 클릭 순서대로 클릭\n",
    "        page[i].click()\n",
    "\n",
    "        time.sleep(0.01)\n",
    "\n",
    "        #셀레니움으로 열어서 페이지 정보 가져오기\n",
    "        html = driver.page_source\n",
    "        soup = bs(html,'html.parser')\n",
    "\n",
    "        #작품 썸네일 이미지\n",
    "        img=soup.select('#content > div.comicinfo > div.thumb > a > img')[0]['src']\n",
    "\n",
    "        img_list.append(img)\n",
    "\n",
    "        #작가님 닉네임 수집\n",
    "        artist = soup.select('#content > div.comicinfo > div.detail > h2 > span.wrt_nm')\n",
    "        artist_list.append(artist[0].string.strip())\n",
    "\n",
    "        #줄거리 링크 \n",
    "        story=soup.select('#content > div.comicinfo > div.detail > p:nth-child(2)')\n",
    "        story_list.append(story[0].get_text())\n",
    "\n",
    "        #작품 장르 수집\n",
    "        genre = soup.select('#content > div.comicinfo > div.detail > p.detail_info > span.genre')\n",
    "        genre_list.append(genre[0].string)\n",
    "\n",
    "        # 최신 별점 평균 점수 수집 (최대 10화 분량) : 이부분은 참조함\n",
    "        # https://prod.velog.io/@2taesung/wt.gg-%EB%84%A4%EC%9D%B4%EB%B2%84-%EC%9B%B9%ED%88%B0-%ED%81%AC%EB%A1%A4%EB%A7%81\n",
    "        score = soup.find_all('strong')\n",
    "\n",
    "        scorelist=[] ; ii=9\n",
    "        while score[ii].text[0].isnumeric()==True:\n",
    "            scorelist.append(float(score[ii].text))\n",
    "            ii +=1\n",
    "            if len(scorelist) == 3:\n",
    "              break\n",
    "        score_list.append(sum(scorelist)/len(scorelist))\n",
    "\n",
    "        time.sleep(0.5)\n",
    "\n",
    "        driver.back()\n",
    "\n",
    "        time.sleep(0.2)\n",
    "\n",
    "        page.clear()\n",
    "\n",
    "        time.sleep(0.01)\n",
    "        \n",
    "    df = pd.DataFrame(zip(artist_list, genre_list, score_list, story_list,img_list), \n",
    "                      columns = ['Artist', 'Genre', 'Score(recent 10)', 'Story', 'Image'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ea3769",
   "metadata": {},
   "source": [
    "**완결 웹툰 크롤링하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946019d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "URL = 'https://comic.naver.com/webtoon/finish'\n",
    "html = requests.get(URL).text # html 문서 전체를 긁어서 출력해줌, .text는 태그 제외하고 text만 출력되게 함\n",
    "soup = bs(html, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca483044",
   "metadata": {},
   "source": [
    "**링크 주소와 제목 가져오기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c73394ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "link_list = []\n",
    "title_list = []\n",
    "\n",
    "for i in tqdm(range(1,1283)): #완결 웹툰 가장 마지막 인덱스(현재는 크롤링 날짜 기준)\n",
    "    tl_tag=soup.select(f'#content > div.list_area > ul > li:nth-child({i}) > dl > dt > a')\n",
    "    title = tl_tag[0]['title']\n",
    "    link = tl_tag[0]['href']\n",
    "    \n",
    "    title_list.append(title)\n",
    "    link_list.append(f'https://comic.naver.com{link}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1314577",
   "metadata": {},
   "source": [
    "**링크 주소, 제목 데이터 프레임으로 만들고 csv로 저장하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e82e0bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final_tl = pd.DataFrame(zip(title_list,link_list), columns = ['Title', 'Link'])\n",
    "df_final_tl.to_csv('naver_webtoon_final_title_link.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2fe9d4",
   "metadata": {},
   "source": [
    "**저장된 데이터 프레임 불러와 확인 후, 제목 리스트 뽑아 함수에 넣어 크롤링 진행하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64322c70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 백업하기\n",
    "df_final_tl = pd.read_csv('naver_webtoon_final_title_link.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdb88697",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_list = df_final_tl['Title'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d294f0bd",
   "metadata": {},
   "source": [
    "**함수 돌리기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebf867d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finish = naver_crawling_finish(title_list, URL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426f9cd5",
   "metadata": {},
   "source": [
    "**데이터 프레임으로 변환하고 csv로 저장하기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca7b090",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_finish.to_csv('naver_webtoon_finish_without_tl.csv', index=False)\n",
    "df_final_etl = pd.read_csv('naver_webtoon_finish_without_tl.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0caa98f7",
   "metadata": {},
   "source": [
    "**데이터 프레임 합치고 연재중 웹툰 csv와 순서 맞추기**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b477d791",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_final_tl,df_final_etl],axis=1, join='inner') \n",
    "df=df[['Title', 'Artist', 'Genre', 'Score(recent 10)', 'Story', 'Image', 'Link']]\n",
    "df.to_csv('naver_webtoon_finish.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295007d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.read_csv('naver_webtoon_finish.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6842a62a",
   "metadata": {},
   "source": [
    "## 네이버 웹툰 회차별 썸네일 크롤링하기\n",
    "출처: [사이트 링크](https://domdom.tistory.com/entry/%ED%81%AC%EB%A1%A4%EB%A7%81-%ED%8C%8C%EC%9D%B4%EC%8D%AC%EC%9C%BC%EB%A1%9C-%EB%84%A4%EC%9D%B4%EB%B2%84-%EC%9B%B9%ED%88%B0-%EC%86%8C%EA%B0%9C-%EB%B0%8F-%ED%9A%8C%EC%B0%A8-%EC%A0%95%EB%B3%B4-%EA%B0%80%EC%A0%B8%EC%98%A4%EA%B8%B0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45e6ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = pd.read_csv('naver_webtoon_real.csv')\n",
    "df2 = pd.read_csv('naver_webtoon_finish.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee63a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df1,df2], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9df55754",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수 만들기\n",
    "\n",
    "def bring_thumb_images(df):\n",
    "    imglist = []\n",
    "    cnt=1\n",
    "    for i in tqdm(range(len(df))):\n",
    "        \n",
    "        print(df['Title'][i], '수집 중')\n",
    "        \n",
    "        # 웹툰의 각 회차별 썸네일 가져오기\n",
    "        page = 1\n",
    "        imgSrc=[]\n",
    "        while True:\n",
    "            url = df['Link'][i]+f\"&page={str(page)}\"\n",
    "            res = requests.get(url)\n",
    "            soup = bs(res.text, 'lxml')\n",
    "\n",
    "            viewList = soup.select('.viewList tr')\n",
    "\n",
    "\n",
    "            for view in viewList[3:]: # 배너 제외\n",
    "                imgSrc.append(view.select_one('a > img').attrs.get('src'))\n",
    "                cnt += 1\n",
    "            time.sleep(0.01)\n",
    "\n",
    "            if soup.select_one('a.next') == None:\n",
    "                print('last page was ' + str(page))\n",
    "                print(f'1830 중 {i+1} 완료')\n",
    "                break\n",
    "            page = page + 1\n",
    "            time.sleep(0.01)\n",
    "        \n",
    "        #위에서 만들어진 리스트를 원하는 형태로 바꾸어 하나의 리스트로 담아주기\n",
    "        img_str = \" π \".join(imgSrc)\n",
    "        imglist.append(img_str)\n",
    "    \n",
    "    print(cnt)\n",
    "    \n",
    "    return imglist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef59be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = bring_thumb_images(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe54c2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_thumb = pd.DataFrame({'Thumbs': img })\n",
    "df_thumb.to_csv('naver_webtoon_thumbs.csv', index=False)\n",
    "\n",
    "df = pd.concat([df, df_thumb], axis=1)\n",
    "df.to_csv('naver_webtoon_all_with_thumbs.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
